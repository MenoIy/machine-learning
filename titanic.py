# -*- coding: utf-8 -*-
"""Titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fBbcOIp76NryExElVB75E4Ad22N8DfCT
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

path = './drive/My Drive/titanic/'
list = os.listdir(path)
train_data = pd.read_csv(path + list[1])
test_data = pd.read_csv(path + list[2])
gendre_data = pd.read_csv(path + list[0])

train_data.head()

train_data.shape

train_data.info

train_data.shape

train_data.count()

fig = plt.figure(figsize=(18, 6))
plt.subplot2grid((2, 3), (0, 0))
train_data['Survived'].value_counts(normalize=True) .plot(kind = "bar", alpha=0.5)
plt.title("Survived")

plt.subplot2grid((2, 3), (0, 1))
plt.scatter(train_data['Survived'], train_data['Age'], alpha=0.1)
plt.title("Survived x age")

plt.subplot2grid((2, 3), (0, 2))
train_data['Pclass'].value_counts(normalize=True) .plot(kind = "bar", alpha=0.5)
plt.title("Class")

plt.subplot2grid((2, 3), (1, 0), colspan=2)
for x in [1, 2, 3] :
  train_data['Age'][train_data['Pclass'] == x].plot(kind = "kde")
plt.title("Class x Age")
plt.legend(("1", "2", "3"))

plt.subplot2grid((2, 3), (1, 2))
train_data['Embarked'].value_counts(normalize=True) .plot(kind = "bar", alpha=0.5)
plt.title("Embarked")

plt.show

fig = plt.figure(figsize=(18, 6))
female_color = "#FA0000"

plt.subplot2grid((3, 4), (0, 0))
train_data['Survived'].value_counts(normalize=True) .plot(kind = "bar", alpha=0.5, color = "#00FF00")
plt.title("Survived")

plt.subplot2grid((3, 4), (0, 1))
train_data['Survived'][train_data['Sex'] == "male"].value_counts(normalize=True) .plot(kind = "bar", alpha=0.5, color = "#0000FF")
plt.title("Men Survived")

plt.subplot2grid((3, 4), (0, 2))
train_data['Survived'][train_data['Sex'] == "female"].value_counts(normalize=True) .plot(kind = "bar", alpha=0.5, color= female_color)
plt.title("Women Survived")


plt.subplot2grid((3, 4), (0, 3))
train_data['Sex'][train_data['Survived'] == 1].value_counts(normalize=True) .plot(kind = "bar", alpha=0.5, color= [female_color, "#0000FF"])
plt.title("Sex of Survived")

plt.subplot2grid((3, 4), (1, 0), colspan=4)
for x in [1, 2, 3] :
  train_data['Survived'][train_data['Pclass'] == x].plot(kind = "kde")
plt.title("Class x Survived")
plt.legend(("1", "2", "3"))

plt.subplot2grid((3, 4), (2, 0))
train_data['Survived'][(train_data['Sex'] == "male") & (train_data['Pclass'] == 1)].value_counts(normalize=True) .plot(kind = "bar", alpha=0.5, color = "#0000FF")
plt.title("Rich Men Survived")

plt.subplot2grid((3, 4), (2, 1))
train_data['Survived'][(train_data['Sex'] == "male") & (train_data['Pclass'] == 3)].value_counts(normalize=True) .plot(kind = "bar", alpha=0.5, color = "#0000FF")
plt.title("Poor Men Survived")

plt.subplot2grid((3, 4), (2, 2))
train_data['Survived'][(train_data['Sex'] == "female") & (train_data['Pclass'] == 1)].value_counts(normalize=True) .plot(kind = "bar", alpha=0.5, color = female_color)
plt.title("Rich Women Survived")

plt.subplot2grid((3, 4), (2, 3))
train_data['Survived'][(train_data['Sex'] == "female") & (train_data['Pclass'] == 3)].value_counts(normalize=True) .plot(kind = "bar", alpha=0.5, color = female_color)
plt.title("Poor Women Survived")

plt.show()

train_data["Hyp"] = 0
  train_data.loc[train_data["Sex"] == "female", "Hyp"] = 1
  train_data["Result"] = 0
  train_data.loc[train_data["Survived"] == train_data["Hyp"], "Result"] = 1
  print(train_data["Result"].value_counts(normalize=True))

"""Transform string information to value"""

def clain_data(data):
  data["Fare"] = data["Fare"].fillna(data["Fare"].dropna().median())
  data["Age"] = data["Age"].fillna(data["Age"].dropna().median())

  data.loc[data["Sex"] == "male", "Sex"] = 0
  data.loc[data["Sex"] == "female", "Sex"] = 1

  data["Embarked"] = data["Embarked"].fillna("S")
  data.loc[data["Embarked"] == "S", "Embarked"] = 0
  data.loc[data["Embarked"] == "C", "Embarked"] = 1
  data.loc[data["Embarked"] == "Q", "Embarked"] = 2

from sklearn import linear_model, preprocessing, tree , model_selection
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

train = pd.read_csv(path + list[1])
clain_data(train)
features_names = ["Pclass", "Age", "Sex", "Fare" ,"SibSp" , "Embarked", "Parch"]

target = train["Survived"].values
features = train[features_names].values
classifier = linear_model.LogisticRegression()
classifier_ = classifier.fit(features, target)

print(classifier_.score(features, target))

poly = preprocessing.PolynomialFeatures(degree=2)
poly_features = poly.fit_transform(features)
classifier_ = classifier.fit(poly_features, target)
print(classifier_.score(poly_features, target))

decision_tree = tree.DecisionTreeClassifier(random_state = 1, max_depth=7, min_samples_split=2)
decision_tree_ = decision_tree.fit(features, target)

print(decision_tree_.score(features, target))

scores  = model_selection.cross_val_score(decision_tree, features, target, scoring='accuracy', cv=50)
print(scores)
print(scores.mean())
tree.export_graphviz(decision_tree_, feature_names=features_names, out_file="tree.dot")
from google.colab import files
files.download("tree.dot")